{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUDTAaAkyjts"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LOAlXXjxz4U",
        "outputId": "16138647-d666-4b87-f22e-d5524ef4c7bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8LHlRTE4MQ"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Silakan upload cnn_grc.zip ke files.\n",
        "\n",
        "Alternatif lain, bisa juga dataset di upload ke storage lain lalu nanti didownload dengan cmommand lin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koWK-eoKEnnc",
        "outputId": "fef787bb-19df-4405-b1e2-f97ad7188c79"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/ForColab/cnn_grc.zip\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/ForColab/cnn_grc.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeyp8cdXE9QA"
      },
      "source": [
        "# extract file zip\n",
        "# tanda seru artinya ini bukan perintah Python, melainkan perintah command prompt ubuntu\n",
        "! unzip cnn_grc.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW-ey9wjFE0O"
      },
      "source": [
        "import torch as pt # library utama pytorch\n",
        "import numpy as np # numerical python\n",
        "import pandas as pd # bermain dataset\n",
        "import copy # untuk copy2 an\n",
        "\n",
        "# libray lain pytorch untuk membangun arsitektur\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "\n",
        "# library dar pytorch untuk pengelolaan dataset khususnya data citra\n",
        "from torchvision import transforms, datasets, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN4AlMDbFL4X"
      },
      "source": [
        "train_dir = \"/content/drive/Shareddrives/Deep Learning/TRAIN\"\n",
        "test_dir = \"/content/drive/Shareddrives/Deep Learning/TEST\"\n",
        "\n",
        "# fungsi transform bertugas untuk \"mengedit\" data yang masuk\n",
        "# macam-macam perintah yang bisa dilakukan bisa cek di sini: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "train_transform = transforms.Compose([ # proses transform dilakukan secara berurutan\n",
        "    transforms.RandomHorizontalFlip(p=0.2),\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(224), # 1. di crop ukuran 150x150 di tengah citra\n",
        "    transforms.ToTensor(), # 2. di ubah ke tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(500),          \n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# load dataset dengan format folder yang sesuai lalu aplikasikan transformasi ke data yang dibaca\n",
        "# hasil dari proses ini adalah sebuah list berelemen tuple (tensor_citra, label) disebut dengan objek datasets\n",
        "train_img = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "test_img = datasets.ImageFolder(test_dir, transform=test_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gf-xAg7FOAK"
      },
      "source": [
        "# bagian ini intinya mengubah objek datasets di atas ke format yang lebih baik :)\n",
        "# insyaAllah akan dijelaskan di pertemuan selanjutnya\n",
        "trainloaders = pt.utils.data.DataLoader(train_img, batch_size=16, shuffle=True)\n",
        "testloaders = pt.utils.data.DataLoader(test_img, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q-a1tBeFPEg",
        "outputId": "8e799e08-b0ef-4233-82d7-c8cf67a74103"
      },
      "source": [
        "# Informasi dari dataset kita\n",
        "print(\"train_img type   :\",type(train_img)) # objek datasets\n",
        "\n",
        "print(\"train_img length :\",len(train_img)) # 515 data train\n",
        "print(\"test_img length :\",len(test_img)) # 66 data test\n",
        "\n",
        "print(\"train_img classes:\",train_img.classes) # nama kelas\n",
        "print(\"train_img classes:\",train_img.class_to_idx) # nama kelas\n",
        "\n",
        "print(\"train_img[0] type:\",type(train_img[0])) # tuple (A, B)\n",
        "print(\"train_img[0][0]  :\",train_img[0][0].size()) # tensor citra\n",
        "print(\"train_img[0][1]  :\",train_img[0][1]) # label\n",
        "\n",
        "# variabel banyak data\n",
        "len_train = len(train_img)\n",
        "len_test = len(test_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_img type   : torchvision.datasets.folder.ImageFolder\n",
            "train_img length : 474\n",
            "test_img length : 60\n",
            "train_img classes: ['PENSIL', 'PULPEN', 'SPIDOL']\n",
            "train_img classes: {'PENSIL': 0, 'PULPEN': 1, 'SPIDOL': 2}\n",
            "train_img[0] type: <class 'tuple'>\n",
            "train_img[0][0]  : torch.Size([3, 224, 224])\n",
            "train_img[0][1]  : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-AgihZSFS7c"
      },
      "source": [
        "class Net(nn.Module):\n",
        "   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        # ukuran sisi = ((ukuran - kernel_size + 2 * padding) / stride + 1)\n",
        "        # hasil flatten = sisi * sisi * feature_maps\n",
        "        self.fc1 = nn.Linear(42632, 3) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # forward propagation\n",
        "        x = self.conv1(x) # convolusi\n",
        "        x = F.relu(x) # fungsi aktivasi\n",
        "        x = self.pool(x) # pooling\n",
        "        x = x.reshape(x.shape[0], -1) # flattening\n",
        "        x = F.relu(self.fc1(x)) # layer biasa\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtnlTLyhFaXd"
      },
      "source": [
        "modelkita = Net().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4SKMTsTFb7O",
        "outputId": "bab6629e-7ae9-4f6c-84a8-d52145baa8d6"
      },
      "source": [
        "modelkita"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=42632, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clMvbl_qFd0s",
        "outputId": "ec711593-c990-4ed6-e4b5-ec7f355e5f71"
      },
      "source": [
        "modelkita = models.resnet18(pretrained=True)\n",
        "\n",
        "#freezing\n",
        "for param in modelkita.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# hapus layer terakhir\n",
        "modelkita.fc = nn.Linear(512, 3)\n",
        "\n",
        "modelkita = modelkita.cuda()\n",
        "print(modelkita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR1RYqfcFgRc"
      },
      "source": [
        "optimizer = pt.optim.Adagrad(modelkita.parameters(), lr=0.01) # algoritma training\n",
        "criterion = nn.CrossEntropyLoss() # rumus error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dFvKIjZFiOh",
        "outputId": "7e5ed8a7-e648-46c6-ba98-1ca3ab2cf101"
      },
      "source": [
        "  modelkita.train()\n",
        "for i in range(5): # 30 epoch\n",
        "\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in trainloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "        \n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        E.backward()       \n",
        "\n",
        "        # update\n",
        "        optimizer.step() \n",
        "\n",
        "    print(rata2error/len_train, jumlahbenar/len_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>) 0.6286919831223629\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<DivBackward0>) 0.8713080168776371\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<DivBackward0>) 0.9029535864978903\n",
            "tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>) 0.9177215189873418\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<DivBackward0>) 0.919831223628692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0r0jXzCFl6S",
        "outputId": "52a7ff03-828e-4b74-bcc2-ba7739792c93"
      },
      "source": [
        "modelkita.eval()\n",
        "\n",
        "with pt.no_grad():\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in testloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "\n",
        "    print(rata2error/len_test, jumlahbenar/len_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2484, device='cuda:0') 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa459NZfFp6S"
      },
      "source": [
        "pt.save(modelkita, \"modelkita_v2.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJHIcIorFtbM"
      },
      "source": [
        "# load model\n",
        "modelbaru = pt.load(\"modelkita_v2.pth\", map_location=pt.device(\"cpu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7mEAEyaFulC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e3ac73-e7fa-4516-fc21-3e2268d5eb92"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "modelbaru.eval()\n",
        "\n",
        "# load single image\n",
        "single_img = Image.open(\"/content/drive/Shareddrives/Deep Learning/TEST/File_000.jpeg\")\n",
        "\n",
        "# transform\n",
        "single_img_transformed = test_transform(single_img)\n",
        "\n",
        "Y = modelbaru( single_img_transformed.unsqueeze(0) )\n",
        "\n",
        "prediksi = pt.max(Y, dim=1).indices\n",
        "print(prediksi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uchZgC-Fxxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf70c9dc-370d-40bd-eadf-de9766675020"
      },
      "source": [
        "prediksi.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}